from __future__ import annotations

from typing import Optional
from xmlrpc.client import boolean

import numpy as np
from numpy.typing import NDArray
from qolmat.imputations.rpca.rpca import RPCA
from qolmat.imputations.rpca import utils
import tqdm


class PcpRPCA(RPCA):
    """
    This class implements the basic RPCA decomposition using Alternating Lagrangian Multipliers.

    References
    ----------
    CandÃ¨s, Emmanuel J., et al. "Robust principal component analysis."
    Journal of the ACM (JACM) 58.3 (2011): 1-37

    Parameters
    ----------
    mu: Optional
        parameter for the convergence and shrinkage operator
    lam: Optional
        penalizing parameter for the sparse matrix
    """

    def __init__(
        self,
        n_rows: Optional[int] = None,
        mu: Optional[float] = None,
        lam: Optional[float] = None,
        maxIter: Optional[int] = int(1e4),
        tol: Optional[float] = 1e-6,
        verbose: bool = False,
    ) -> None:

        super().__init__(n_rows=n_rows, maxIter=maxIter, tol=tol, verbose=verbose)
        self.mu = mu
        self.lam = lam

    def get_params(self):
        dict_params = super().get_params()
        dict_params["mu"] = self.mu
        dict_params["lam"] = self.lam
        return dict_params

    def get_params_scale(self, signal):
        D_init, _ = self._prepare_data(signal=signal)
        proj_D = utils.impute_nans(D_init, method="median")
        mu = np.prod(proj_D.shape) / (4.0 * utils.l1_norm(self.proj_D))
        lam = 1 / np.sqrt(np.max(self.proj_D.shape))
        dict_params = {"mu": mu, "lam": lam}
        return dict_params

    def fit_transform(self, signal: NDArray, return_basis: boolean = False) -> PcpRPCA:
        """
        Compute the RPCA decomposition of a matrix based on the PCP method

        Parameters
        ----------
        signal : NDArray
            Observations
        """
        self.input_data = "2DArray"
        D_init, n_add_values = self._prepare_data(signal=signal)
        proj_D = utils.impute_nans(D_init, method="median")

        if self.mu is None:
            self.mu = np.prod(proj_D.shape) / (4.0 * utils.l1_norm(proj_D))

        if self.lam is None:
            self.lam = 1 / np.sqrt(np.max(proj_D.shape))

        D_norm = np.linalg.norm(proj_D, "fro")

        n, m = D_init.shape
        A = np.zeros((n, m))
        Y = np.zeros((n, m))

        errors = []
        for iteration in tqdm.tqdm(range(self.maxIter)):
            X = utils.svd_thresholding(proj_D - A + Y / self.mu, 1 / self.mu)
            A = utils.soft_thresholding(proj_D - X + Y / self.mu, self.lam / self.mu)
            Y += self.mu * (proj_D - X - A)

            errors.append(np.linalg.norm(proj_D - X - A, "fro") / D_norm)
            if errors[-1] <= self.tol:
                if self.verbose:
                    print(f"Converged in {iteration} iterations")
                break

        if return_basis:
            U, _, Vh = np.linalg.svd(X, full_matrices=False, compute_uv=True)
            result = [U, Vh]
        else:
            result = []

        if n_add_values > 0:
            X.flat[-n_add_values:] = np.nan
            A.flat[-n_add_values:] = np.nan

        if self.input_data == "2DArray":
            result = [X, A, errors] + result
        elif self.input_data == "1DArray":
            result = [X.T.flatten(), A.T.flatten(), errors] + result
        else:
            raise ValueError("Data shape not recognized")
        return tuple(result)
